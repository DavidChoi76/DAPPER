<!-- Search file for "CHANGE" for my own changes -->
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dapper.admin API documentation</title>
<meta name="description" content="High-level API. I.e. the main &#34;user-interface&#34; …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<link rel="preconnect" href="https://www.google.com">
<script async src="https://cse.google.com/cse.js?cx=017837193012385208679:pey8ky8gdqw"></script>
<style>
.gsc-control-cse {padding:0 !important;margin-top:1em}
body.gsc-overflow-hidden #sidebar {overflow: visible;}
</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<link rel="icon" href="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo.png">
<!-- Dont work coz pdoc already defines these:
<title>DAPPER doc</title>
<meta name="description" content="Data Assimilation with Python: a Package for Experimental Research" />
-->
<a href="https://github.com/nansencenter/DAPPER" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dapper.admin</code></h1>
</header>
<section id="section-intro">
<p>High-level API. I.e. the main "user-interface".</p>
<p>Used for experiment (<code>xp</code>) specification/administration.
Highlights:</p>
<ul>
<li><code><a title="dapper.admin.Operator" href="#dapper.admin.Operator">Operator</a></code></li>
<li><code><a title="dapper.admin.HiddenMarkovModel" href="#dapper.admin.HiddenMarkovModel">HiddenMarkovModel</a></code></li>
<li><code><a title="dapper.admin.da_method" href="#dapper.admin.da_method">da_method()</a></code> decorator (creates <code>xp</code> objects)</li>
<li><code><a title="dapper.admin.xpList" href="#dapper.admin.xpList">xpList</a></code> (subclass of list for <code>xp</code> objects)</li>
<li><code><a title="dapper.admin.run_experiment" href="#dapper.admin.run_experiment">run_experiment()</a></code> (run experiment specifiied by an <code>xp</code>)</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;High-level API. I.e. the main &#34;user-interface&#34;.

Used for experiment (`xp`) specification/administration.
Highlights:

- `Operator`
- `HiddenMarkovModel`
- `da_method` decorator (creates `xp` objects)
- `xpList` (subclass of list for `xp` objects)
- `run_experiment` (run experiment specifiied by an `xp`)
&#34;&#34;&#34;

import copy
import dataclasses as dcs
import functools
import inspect
import os
import re
import shutil
import sys
import time
from datetime import datetime
from pathlib import Path
from textwrap import dedent

import dill
import numpy as np

import dapper.dict_tools as dict_tools
import dapper.stats
import dapper.tools.utils as utils
from dapper.dpr_config import rc
from dapper.tools.chronos import Chronology
from dapper.tools.localization import no_localization
from dapper.tools.maths import Id_mat, Id_op
from dapper.tools.randvars import RV, GaussRV
from dapper.tools.remote.uplink import submit_job_GCP
from dapper.tools.stoch import set_seed


class HiddenMarkovModel(dict_tools.NicePrint):
    &#34;&#34;&#34;Container for a Hidden Markov Model (HMM).

    This container contains the specification of a &#34;twin experiment&#34;,
    i.e. an &#34;OSSE (observing system simulation experiment)&#34;.
    &#34;&#34;&#34;

    def __init__(self, Dyn, Obs, t, X0, **kwargs):
        # fmt: off
        self.Dyn = Dyn if isinstance(Dyn, Operator)   else Operator  (**Dyn) # noqa
        self.Obs = Obs if isinstance(Obs, Operator)   else Operator  (**Obs) # noqa
        self.t   = t   if isinstance(t  , Chronology) else Chronology(**t)   # noqa
        self.X0  = X0  if isinstance(X0 , RV)         else RV        (**X0)  # noqa
        # fmt: on

        # Name
        self.name = kwargs.pop(&#34;name&#34;, &#34;&#34;)
        if not self.name:
            name = inspect.getfile(inspect.stack()[1][0])
            try:
                self.name = str(Path(name).relative_to(rc.dirs.dapper/&#39;mods&#39;))
            except ValueError:
                self.name = str(Path(name))

        # Kwargs
        abbrevs = {&#39;LP&#39;: &#39;liveplotters&#39;}
        for key in kwargs:
            setattr(self, abbrevs.get(key, key), kwargs[key])

        # Defaults
        if not hasattr(self.Obs, &#34;localizer&#34;):
            self.Obs.localizer = no_localization(self.Nx, self.Ny)
        if not hasattr(self, &#34;sectors&#34;):
            self.sectors = {}

        # Validation
        if self.Obs.noise.C == 0 or self.Obs.noise.C.rk != self.Obs.noise.C.M:
            raise ValueError(&#34;Rank-deficient R not supported.&#34;)

    # ndim shortcuts
    @property
    def Nx(self): return self.Dyn.M
    @property
    def Ny(self): return self.Obs.M

    printopts = {&#39;ordering&#39;: [&#39;Dyn&#39;, &#39;Obs&#39;, &#39;t&#39;, &#39;X0&#39;]}

    def simulate(self, desc=&#39;Truth &amp; Obs&#39;):
        &#34;&#34;&#34;Generate synthetic truth and observations.&#34;&#34;&#34;
        Dyn, Obs, chrono, X0 = self.Dyn, self.Obs, self.t, self.X0

        # Init
        xx    = np.zeros((chrono.K   + 1, Dyn.M))
        yy    = np.zeros((chrono.KObs+1, Obs.M))

        xx[0] = X0.sample(1)

        # Loop
        for k, kObs, t, dt in utils.progbar(chrono.ticker, desc):
            xx[k] = Dyn(xx[k-1], t-dt, dt) + np.sqrt(dt)*Dyn.noise.sample(1)
            if kObs is not None:
                yy[kObs] = Obs(xx[k], t) + Obs.noise.sample(1)

        return xx, yy


class Operator(dict_tools.NicePrint):
    &#34;&#34;&#34;Container for operators (models).&#34;&#34;&#34;

    def __init__(self, M, model=None, noise=None, **kwargs):
        self.M = M

        # None =&gt; Identity model
        if model is None:
            model = Id_op()
            kwargs[&#39;linear&#39;] = lambda x, t, dt: Id_mat(M)
        self.model = model

        # None/0 =&gt; No noise
        if isinstance(noise, RV):
            self.noise = noise
        else:
            if noise is None:
                noise = 0
            if np.isscalar(noise):
                self.noise = GaussRV(C=noise, M=M)
            else:
                self.noise = GaussRV(C=noise)

        # Write attributes
        for key, value in kwargs.items():
            setattr(self, key, value)

    def __call__(self, *args, **kwargs):
        return self.model(*args, **kwargs)

    printopts = {&#39;ordering&#39;: [&#39;M&#39;, &#39;model&#39;, &#39;noise&#39;]}


def da_method(*default_dataclasses):
    &#34;&#34;&#34;Wrapper for classes that define DA methods.

    These classes must be defined like dataclasses, except decorated
    by `@da_method()` instead of `@dataclass`.
    They must also define a method called `assimilate`
    which gets slightly enhanced by this wrapper to provide:
        - Initialisation of the `Stats` object
        - `fail_gently` functionality.
        - Duration timing
        - Progressbar naming magic.

    Instances of these classes are what is referred to as `xp`s.
    I.e. `xp`s are essentially just data containers.

    Example:
    &gt;&gt;&gt; @da_method()
    &gt;&gt;&gt; class Sleeper():
    &gt;&gt;&gt;     &#34;Do nothing.&#34;
    &gt;&gt;&gt;     seconds : int  = 10
    &gt;&gt;&gt;     success : bool = True
    &gt;&gt;&gt;     def assimilate(self,*args,**kwargs):
    &gt;&gt;&gt;         for k in utils.progbar(range(self.seconds)):
    &gt;&gt;&gt;             time.sleep(1)
    &gt;&gt;&gt;         if not self.success:
    &gt;&gt;&gt;             raise RuntimeError(&#34;Sleep over. Failing as intended.&#34;)

    Note that `da_method` is actually a &#34;two-level decorator&#34;,
    which is why the empty parenthesis were used above.
    The outer level can be used to define defaults that are re-used
    for similar DA methods:

    Example:
    &gt;&gt;&gt; @dcs.dataclass
    &gt;&gt;&gt; class ens_defaults:
    &gt;&gt;&gt;   infl : float = 1.0
    &gt;&gt;&gt;   rot  : bool  = False
    &gt;&gt;&gt;
    &gt;&gt;&gt; @da_method(ens_defaults)
    &gt;&gt;&gt; class EnKF:
    &gt;&gt;&gt;     N     : int
    &gt;&gt;&gt;     upd_a : str = &#34;Sqrt&#34;
    &gt;&gt;&gt;
    &gt;&gt;&gt;     def assimilate(self,HMM,xx,yy):
    &gt;&gt;&gt;         ...
    &gt;&gt;&gt;
    &gt;&gt;&gt;
    &gt;&gt;&gt; @da_method(ens_defaults)
    &gt;&gt;&gt; class LETKF:
    &gt;&gt;&gt;     ...
    &#34;&#34;&#34;

    def dataclass_with_defaults(cls):
        &#34;&#34;&#34;Decorator based on dataclass.

        This adds `__init__`, `__repr__`, `__eq__`, ...,
        but also includes inherited defaults
        (see https://stackoverflow.com/a/58130805 ),
        and enhances the `assimilate` method.
        &#34;&#34;&#34;

        # Default fields invovle: (1) annotations and (2) attributes.
        def set_field(name, type, val):
            if not hasattr(cls, &#39;__annotations__&#39;):
                cls.__annotations__ = {}
            cls.__annotations__[name] = type
            if not isinstance(val, dcs.Field):
                val = dcs.field(default=val)
            setattr(cls, name, val)

        # APPend default fields without overwriting.
        # Don&#39;t implement (by PREpending?) non-default args -- to messy!
        for D in default_dataclasses:
            # NB: Calling dataclass twice always makes repr=True, so avoid this.
            for F in dcs.fields(dcs.dataclass(D)):
                if F.name not in cls.__annotations__:
                    set_field(F.name, F.type, F)

        # Create new class (NB: old/new classes have same id)
        cls = dcs.dataclass(cls)

        # Shortcut for self.__class__.__name__
        cls.da_method = cls.__name__

        def assimilate(self, HMM, xx, yy, desc=None, **stat_kwargs):
            # Progressbar name
            pb_name_hook = self.da_method if desc is None else desc # noqa
            # Init stats
            self.stats = dapper.stats.Stats(self, HMM, xx, yy, **stat_kwargs)
            # Assimilate
            time_start = time.time()
            _assimilate(self, HMM, xx, yy)
            dapper.stats.register_stat(self.stats, &#34;duration&#34;, time.time()-time_start)

        _assimilate = cls.assimilate
        cls.assimilate = functools.wraps(_assimilate)(assimilate)

        return cls
    return dataclass_with_defaults


def seed_and_simulate(HMM, xp):
    &#34;&#34;&#34;Default experiment setup. Set seed and simulate truth and obs.

    .. note:: `xp.seed` should be an integer. Otherwise:
        If there is no `xp.seed` then then the seed is not set.
        Although different `xp`s will then use different seeds
        (unless you do some funky hacking),
        reproducibility for your script as a whole would still be obtained
        by setting the seed at the outset (i.e. in the script).
        On the other hand, if `xp.seed in [None, &#34;clock&#34;]`
        then the seed is from the clock (for each xp),
        which would not provide exact reproducibility.
    &#34;&#34;&#34;
    set_seed(getattr(xp, &#39;seed&#39;, False))

    xx, yy = HMM.simulate()
    return xx, yy


def run_experiment(xp, label, savedir, HMM,
                   setup=None, free=True, statkeys=False, fail_gently=False,
                   **stat_kwargs):
    &#34;&#34;&#34;Used by `xpList.launch` to run each single experiment.

    This involves steps similar to `example_1.py`, i.e.:

    - `setup`                    : Call function given by user. Should set
                                   params, eg HMM.Force, seed, and return
                                   (simulated/loaded) truth and obs series.
    - `xp.assimilate`            : run DA, pass on exception if fail_gently
    - `xp.stats.average_in_time` : result averaging
    - `xp.avrgs.tabulate`        : result printing
    - `dill.dump`                : result storage
    &#34;&#34;&#34;

    # We should copy HMM so as not to cause any nasty surprises such as
    # expecting param=1 when param=2 (coz it&#39;s not been reset).
    # NB: won&#39;t copy implicitly ref&#39;d obj&#39;s (like L96&#39;s core). =&gt; bug w/ MP?
    hmm = copy.deepcopy(HMM)

    # GENERATE TRUTH/OBS
    xx, yy = setup(hmm, xp)

    # ASSIMILATE
    try:
        xp.assimilate(hmm, xx, yy, label, **stat_kwargs)
    except Exception as ERR:
        if fail_gently:
            xp.crashed = True
            if fail_gently not in [&#34;silent&#34;, &#34;quiet&#34;]:
                utils.print_cropped_traceback(ERR)
        else:
            raise ERR

    # AVERAGE
    xp.stats.average_in_time(free=free)

    # PRINT
    if statkeys:
        statkeys = () if statkeys is True else statkeys
        print(xp.avrgs.tabulate(statkeys))

    # SAVE
    if savedir:
        with open(Path(savedir)/&#34;xp&#34;, &#34;wb&#34;) as FILE:
            dill.dump({&#39;xp&#39;: xp}, FILE)


class xpList(list):
    &#34;&#34;&#34;Subclass of `list` specialized for experiment (&#34;xp&#34;) objects.

    Main use: administrate experiment **launches**.
    Also see: `xpSpace` for experiment **result presentation**.

    Modifications to `list`:

    - `__iadd__` (append) also for single items;
      this is hackey, but convenience is king.
    - `append()` supports `unique` to enable lazy xp declaration.
    - `__getitem__` supports lists.
    - pretty printing (using common/distinct attrs).

    Add-ons:

    - `launch()`
    - `print_averages()`
    - `gen_names()`
    - `inds()` to search by kw-attrs.
    &#34;&#34;&#34;

    def __init__(self, *args, unique=False):
        &#34;&#34;&#34;Initialize without args, or with a list of `xp`s.

        If `unique`: duplicates won&#39;t get appended.
        This makes `append()` (and `__iadd__()`) relatively slow.
        Use `extend()` or `__add__()` to bypass this validation.&#34;&#34;&#34;

        self.unique = unique
        super().__init__(*args)

    def __iadd__(self, xp):
        if not hasattr(xp, &#39;__iter__&#39;):
            xp = [xp]
        for item in xp:
            self.append(item)
        return self

    def append(self, xp):
        &#34;&#34;&#34;Append if not `self.unique` &amp; present.&#34;&#34;&#34;
        if not (self.unique and xp in self):
            super().append(xp)

    def __getitem__(self, keys):
        &#34;&#34;&#34;Indexing, also by a list&#34;&#34;&#34;
        try:
            B = [self[k] for k in keys]    # if keys is list
        except TypeError:
            B = super().__getitem__(keys)  # if keys is int, slice
        if hasattr(B, &#39;__len__&#39;):
            B = xpList(B)                  # Cast
        return B

    def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
        &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

        If strict, then `xp`s lacking a requested attr will not match,
        unless the missingval (e.g. `None`) matches the required value.
        &#34;&#34;&#34;
        def match(xp):
            def missing(v): return missingval if strict else v
            matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
            return all(matches)

        return [i for i, xp in enumerate(self) if match(xp)]

    @property
    def da_methods(self):
        return [xp.da_method for xp in self]

    def split_attrs(self, nomerge=()):
        &#34;&#34;&#34;Compile attrs of all `xp`s; split into distinct, redundant, common.

        Insert `None` if an attribute is distinct but not in `xp`.&#34;&#34;&#34;

        def _aggregate_keys():
            &#34;Aggregate keys from all `xp`&#34;

            if len(self) == 0:
                return []

            # Start with da_method
            aggregate = [&#39;da_method&#39;]

            # Aggregate all other keys
            for xp in self:

                # Get dataclass fields
                try:
                    dc_fields = dcs.fields(xp.__class__)
                    dc_names = [F.name for F in dc_fields]
                    keys = xp.__dict__.keys()
                except TypeError:
                    # Assume namedtuple
                    dc_names = []
                    keys = xp._fields

                # For all potential keys:
                for k in keys:
                    # If not already present:
                    if k not in aggregate:

                        # If dataclass, check repr:
                        if k in dc_names:
                            if dc_fields[dc_names.index(k)].repr:
                                aggregate.append(k)
                        # Else, just append
                        else:
                            aggregate.append(k)

            # Remove unwanted
            excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
            aggregate = dict_tools.complement(aggregate, excluded)
            return aggregate

        distinct, redundant, common = {}, {}, {}

        for key in _aggregate_keys():

            # Want to distinguish actual None&#39;s from empty (&#34;N/A&#34;).
            # =&gt; Don&#39;t use getattr(obj,key,None)
            vals = [getattr(xp, key, &#34;N/A&#34;) for xp in self]

            # Sort (assign dct) into distinct, redundant, common
            if dict_tools.flexcomp(key, *nomerge):
                # nomerge =&gt; Distinct
                dct, vals = distinct, vals
            elif all(vals[0] == v for v in vals):
                # all values equal =&gt; common
                dct, vals = common, vals[0]
            else:
                v0 = next(v for v in vals if &#34;N/A&#34; != v)
                if all(v == &#34;N/A&#34; or v == v0 for v in vals):
                    # all values equal or &#34;N/A&#34; =&gt; redundant
                    dct, vals = redundant, v0
                else:
                    # otherwise =&gt; distinct
                    dct, vals = distinct, vals

            # Replace &#34;N/A&#34; by None
            def sub(v): return None if v == &#34;N/A&#34; else v
            if isinstance(vals, str):
                vals = sub(vals)
            else:
                try:
                    vals = [sub(v) for v in vals]
                except TypeError:
                    vals = sub(vals)

            dct[key] = vals

        return distinct, redundant, common

    def __repr__(self):
        distinct, redundant, common = self.split_attrs()
        s = &#39;&lt;xpList&gt; of length %d with attributes:\n&#39; % len(self)
        s += utils.tab(distinct, headers=&#34;keys&#34;, showindex=True)
        s += &#34;\nOther attributes:\n&#34;
        s += str(dict_tools.AlignedDict({**redundant, **common}))
        return s

    def gen_names(self, abbrev=6, tab=False):
        &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

        - returns *list* of names
        - tabulation is optional
        - attaches (abbreviated) labels to each attribute
        &#34;&#34;&#34;
        distinct, redundant, common = self.split_attrs(nomerge=[&#34;da_method&#34;])
        labels = distinct.keys()
        values = distinct.values()

        # Label abbreviation
        labels = [utils.collapse_str(k, abbrev) for k in labels]

        # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
        def column(lbl, vals):
            return [None if v is None else lbl+&#34;:&#34; for v in vals]
        labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

        # Interlace labels and values
        table = [x for (a, b) in zip(labels, values) for x in (a, b)]

        # Rm da_method label (but keep value)
        table.pop(0)

        # Transpose
        table = list(map(list, zip(*table)))

        # Tabulate
        table = utils.tab(table, tablefmt=&#34;plain&#34;)

        # Rm space between lbls/vals
        table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

        # Rm alignment
        if not tab:
            table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

        return table.splitlines()

    def tabulate_avrgs(self, *args, **kwargs):
        &#34;&#34;&#34;Pretty (tabulated) `repr` of `xps` &amp; their `avrgs.`

        Similar to `stats.tabulate_avrgs`, but for the entire list of `xps`.&#34;&#34;&#34;
        distinct, redundant, common = self.split_attrs()
        averages = dapper.stats.tabulate_avrgs([C.avrgs for C in self], *args, **kwargs)
        columns = {**distinct, &#39;|&#39;: [&#39;|&#39;]*len(self), **averages}  # merge
        return utils.tab(columns, headers=&#34;keys&#34;, showindex=True).replace(&#39;␣&#39;, &#39; &#39;)

    def launch(self, HMM, save_as=&#34;noname&#34;, mp=False,
               setup=seed_and_simulate, fail_gently=None, **kwargs):
        &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

        The results are saved in `rc.dirs[&#39;data&#39;]/save_as`,
        unless `save_as` is False/None.

        Depending on `mp`, `run_experiment` is delegated as follows:

        - `False`: caller process (no parallelisation)
        - `True` or &#34;MP&#34; or an `int`: multiprocessing on this host
        - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
          (Google Cloud Computing with HTCondor).
            - Specify a list of files as `mp[&#34;files&#34;]` to include them
              in working directory of the server workers.
            - In order to use absolute paths, the list should cosist
              of tuples, where the first item is relative to the second
              (which is an absolute path). The root is then not included
              in the working directory of the server.
            - If this dict field is empty, then all python files
              in `sys.path[0]` are uploaded.

        If `setup == None`: use `seed_and_simulate`.
        Specify your own setup function
        (possibly calling `seed_and_simulate`)
        in order to set (general) experiment parameters that are not
        (i.e. those that are not inherently used by the da_method
        of that `xp`).

        See `example_2.py` and `example_3.py` for example use.
        &#34;&#34;&#34;

        # Collect common args forwarded to run_experiment
        kwargs[&#39;HMM&#39;] = HMM
        kwargs[&#34;setup&#34;] = setup

        # Parse mp option
        if not mp:
            mp = dict()
        elif mp in [True, &#34;MP&#34;]:
            mp = dict(server=&#34;local&#34;)
        elif isinstance(mp, int):
            mp = dict(server=&#34;local&#34;, NPROC=mp)
        elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
            mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

        # Parse fail_gently
        if fail_gently is None:
            if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
                fail_gently = False
                # coz cloud processing is entirely de-coupled anyways
            else:
                fail_gently = True
                # True unless otherwise requested
        kwargs[&#34;fail_gently&#34;] = fail_gently

        # Parse save_as
        if save_as in [None, False]:
            assert not mp, &#34;Multiprocessing requires saving data.&#34;
            # Parallelization w/o storing is possible, especially w/ threads.
            # But it involves more complicated communication set-up.
            def xpi_dir(*args): return None
        else:
            save_as = rc.dirs.data / Path(save_as).stem
            save_as /= &#34;run_&#34; + datetime.now().strftime(&#34;%Y-%m-%d__%H:%M:%S&#34;)
            os.makedirs(save_as)
            print(f&#34;Experiment stored at {save_as}&#34;)

            def xpi_dir(i):
                path = save_as / str(i)
                os.mkdir(path)
                return path

        # No parallelization
        if not mp:
            for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
                run_experiment(xp, label, xpi_dir(ixp), **kwargs)

        # Local multiprocessing
        elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
            def run_with_fixed_args(arg):
                xp, ixp = arg
                run_experiment(xp, None, xpi_dir(ixp), **kwargs)
            args = zip(self, range(len(self)))

            utils.disable_progbar          = True
            utils.disable_user_interaction = True
            NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
            from dapper.tools.multiproc import mpd  # will fail on GCP
            with mpd.Pool(NPROC) as pool:
                list(utils.tqdm.tqdm(
                    pool.imap(
                        run_with_fixed_args, args),
                    total=len(self),
                    desc=&#34;Parallel experim&#39;s&#34;,
                    smoothing=0.1))
            utils.disable_progbar          = False
            utils.disable_user_interaction = False

        # Google cloud platform, multiprocessing
        elif mp[&#34;server&#34;] == &#34;GCP&#34;:
            for ixp, xp in enumerate(self):
                with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                    dill.dump(dict(xp=xp), f)

            with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
                dill.dump(kwargs, f)

            # mkdir extra_files
            extra_files = save_as / &#34;extra_files&#34;
            os.mkdir(extra_files)
            # Default files: .py files in sys.path[0] (main script&#39;s path)
            if not mp.get(&#34;files&#34;, []):
                ff = os.listdir(sys.path[0])
                mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
            # Copy files into extra_files
            for f in mp[&#34;files&#34;]:
                if isinstance(f, (str, Path)):
                    # Example: f = &#34;A.py&#34;
                    path = Path(sys.path[0]) / f
                    dst = f
                else:  # instance of tuple(path, root)
                    # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                    path, root = f
                    dst = Path(path).relative_to(root)
                dst = extra_files / dst
                os.makedirs(dst.parent, exist_ok=True)
                try:
                    shutil.copytree(path, dst)  # dir -r
                except OSError:
                    shutil.copy2(path, dst)  # file

            # Loads PWD/xp_{var,com} and calls run_experiment()
            with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
                f.write(dedent(&#34;&#34;&#34;\
                import dill
                from dapper.admin import run_experiment

                # Load
                with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
                with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

                # User-defined code
                %s

                # Run
                result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
                &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

            with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
                f.write(&#34;\n&#34;.join([
                    &#34;data_root: &#39;$cwd&#39;&#34;,
                    &#34;liveplotting: no&#34;,
                    &#34;welcome_message: no&#34;]))
            submit_job_GCP(save_as)

        return save_as


def get_param_setter(param_dict, **glob_dict):
    &#34;&#34;&#34;Mass creation of `xp`&#39;s by combining the value lists in the parameter dicts.

    The parameters are trimmed to the ones available for the given method.
    This is a good deal more efficient than relying on xpList&#39;s unique=True.

    Beware! If, eg., `infl` or `rot` are in the param_dict, aimed at the EnKF,
    but you forget that they are also attributes some method where you don&#39;t
    actually want to use them (eg. SVGDF),
    then you&#39;ll create many more than you intend.
    &#34;&#34;&#34;
    def for_params(method, **fixed_params):
        dc_fields = [f.name for f in dcs.fields(method)]
        params = dict_tools.intersect(param_dict, dc_fields)
        params = dict_tools.complement(params, fixed_params)
        params = {**glob_dict, **params}  # glob_dict 1st

        def xp1(dct):
            xp = method(**dict_tools.intersect(dct, dc_fields), **fixed_params)
            for key, v in dict_tools.intersect(dct, glob_dict).items():
                setattr(xp, key, v)
            return xp

        return [xp1(dct) for dct in dict_tools.prodct(params)]
    return for_params</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dapper.admin.da_method"><code class="name flex">
<span>def <span class="ident">da_method</span></span>(<span>*default_dataclasses)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper for classes that define DA methods.</p>
<p>These classes must be defined like dataclasses, except decorated
by <code>@da_method()</code> instead of <code>@dataclass</code>.
They must also define a method called <code>assimilate</code>
which gets slightly enhanced by this wrapper to provide:
- Initialisation of the <code>Stats</code> object
- <code>fail_gently</code> functionality.
- Duration timing
- Progressbar naming magic.</p>
<p>Instances of these classes are what is referred to as <code>xp</code>s.
I.e. <code>xp</code>s are essentially just data containers.</p>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; @da_method()
&gt;&gt;&gt; class Sleeper():
&gt;&gt;&gt;     &quot;Do nothing.&quot;
&gt;&gt;&gt;     seconds : int  = 10
&gt;&gt;&gt;     success : bool = True
&gt;&gt;&gt;     def assimilate(self,*args,**kwargs):
&gt;&gt;&gt;         for k in utils.progbar(range(self.seconds)):
&gt;&gt;&gt;             time.sleep(1)
&gt;&gt;&gt;         if not self.success:
&gt;&gt;&gt;             raise RuntimeError(&quot;Sleep over. Failing as intended.&quot;)
</code></pre>
<p>Note that <code><a title="dapper.admin.da_method" href="#dapper.admin.da_method">da_method()</a></code> is actually a "two-level decorator",
which is why the empty parenthesis were used above.
The outer level can be used to define defaults that are re-used
for similar DA methods:</p>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; @dcs.dataclass
&gt;&gt;&gt; class ens_defaults:
&gt;&gt;&gt;   infl : float = 1.0
&gt;&gt;&gt;   rot  : bool  = False
&gt;&gt;&gt;
&gt;&gt;&gt; @da_method(ens_defaults)
&gt;&gt;&gt; class EnKF:
&gt;&gt;&gt;     N     : int
&gt;&gt;&gt;     upd_a : str = &quot;Sqrt&quot;
&gt;&gt;&gt;
&gt;&gt;&gt;     def assimilate(self,HMM,xx,yy):
&gt;&gt;&gt;         ...
&gt;&gt;&gt;
&gt;&gt;&gt;
&gt;&gt;&gt; @da_method(ens_defaults)
&gt;&gt;&gt; class LETKF:
&gt;&gt;&gt;     ...
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def da_method(*default_dataclasses):
    &#34;&#34;&#34;Wrapper for classes that define DA methods.

    These classes must be defined like dataclasses, except decorated
    by `@da_method()` instead of `@dataclass`.
    They must also define a method called `assimilate`
    which gets slightly enhanced by this wrapper to provide:
        - Initialisation of the `Stats` object
        - `fail_gently` functionality.
        - Duration timing
        - Progressbar naming magic.

    Instances of these classes are what is referred to as `xp`s.
    I.e. `xp`s are essentially just data containers.

    Example:
    &gt;&gt;&gt; @da_method()
    &gt;&gt;&gt; class Sleeper():
    &gt;&gt;&gt;     &#34;Do nothing.&#34;
    &gt;&gt;&gt;     seconds : int  = 10
    &gt;&gt;&gt;     success : bool = True
    &gt;&gt;&gt;     def assimilate(self,*args,**kwargs):
    &gt;&gt;&gt;         for k in utils.progbar(range(self.seconds)):
    &gt;&gt;&gt;             time.sleep(1)
    &gt;&gt;&gt;         if not self.success:
    &gt;&gt;&gt;             raise RuntimeError(&#34;Sleep over. Failing as intended.&#34;)

    Note that `da_method` is actually a &#34;two-level decorator&#34;,
    which is why the empty parenthesis were used above.
    The outer level can be used to define defaults that are re-used
    for similar DA methods:

    Example:
    &gt;&gt;&gt; @dcs.dataclass
    &gt;&gt;&gt; class ens_defaults:
    &gt;&gt;&gt;   infl : float = 1.0
    &gt;&gt;&gt;   rot  : bool  = False
    &gt;&gt;&gt;
    &gt;&gt;&gt; @da_method(ens_defaults)
    &gt;&gt;&gt; class EnKF:
    &gt;&gt;&gt;     N     : int
    &gt;&gt;&gt;     upd_a : str = &#34;Sqrt&#34;
    &gt;&gt;&gt;
    &gt;&gt;&gt;     def assimilate(self,HMM,xx,yy):
    &gt;&gt;&gt;         ...
    &gt;&gt;&gt;
    &gt;&gt;&gt;
    &gt;&gt;&gt; @da_method(ens_defaults)
    &gt;&gt;&gt; class LETKF:
    &gt;&gt;&gt;     ...
    &#34;&#34;&#34;

    def dataclass_with_defaults(cls):
        &#34;&#34;&#34;Decorator based on dataclass.

        This adds `__init__`, `__repr__`, `__eq__`, ...,
        but also includes inherited defaults
        (see https://stackoverflow.com/a/58130805 ),
        and enhances the `assimilate` method.
        &#34;&#34;&#34;

        # Default fields invovle: (1) annotations and (2) attributes.
        def set_field(name, type, val):
            if not hasattr(cls, &#39;__annotations__&#39;):
                cls.__annotations__ = {}
            cls.__annotations__[name] = type
            if not isinstance(val, dcs.Field):
                val = dcs.field(default=val)
            setattr(cls, name, val)

        # APPend default fields without overwriting.
        # Don&#39;t implement (by PREpending?) non-default args -- to messy!
        for D in default_dataclasses:
            # NB: Calling dataclass twice always makes repr=True, so avoid this.
            for F in dcs.fields(dcs.dataclass(D)):
                if F.name not in cls.__annotations__:
                    set_field(F.name, F.type, F)

        # Create new class (NB: old/new classes have same id)
        cls = dcs.dataclass(cls)

        # Shortcut for self.__class__.__name__
        cls.da_method = cls.__name__

        def assimilate(self, HMM, xx, yy, desc=None, **stat_kwargs):
            # Progressbar name
            pb_name_hook = self.da_method if desc is None else desc # noqa
            # Init stats
            self.stats = dapper.stats.Stats(self, HMM, xx, yy, **stat_kwargs)
            # Assimilate
            time_start = time.time()
            _assimilate(self, HMM, xx, yy)
            dapper.stats.register_stat(self.stats, &#34;duration&#34;, time.time()-time_start)

        _assimilate = cls.assimilate
        cls.assimilate = functools.wraps(_assimilate)(assimilate)

        return cls
    return dataclass_with_defaults</code></pre>
</details>
</dd>
<dt id="dapper.admin.seed_and_simulate"><code class="name flex">
<span>def <span class="ident">seed_and_simulate</span></span>(<span>HMM, xp)</span>
</code></dt>
<dd>
<div class="desc"><p>Default experiment setup. Set seed and simulate truth and obs.</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;<code>xp.seed</code> should be an integer. Otherwise:</p>
<p>If there is no <code>xp.seed</code> then then the seed is not set.
Although different <code>xp</code>s will then use different seeds
(unless you do some funky hacking),
reproducibility for your script as a whole would still be obtained
by setting the seed at the outset (i.e. in the script).
On the other hand, if <code>xp.seed in [None, "clock"]</code>
then the seed is from the clock (for each xp),
which would not provide exact reproducibility.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def seed_and_simulate(HMM, xp):
    &#34;&#34;&#34;Default experiment setup. Set seed and simulate truth and obs.

    .. note:: `xp.seed` should be an integer. Otherwise:
        If there is no `xp.seed` then then the seed is not set.
        Although different `xp`s will then use different seeds
        (unless you do some funky hacking),
        reproducibility for your script as a whole would still be obtained
        by setting the seed at the outset (i.e. in the script).
        On the other hand, if `xp.seed in [None, &#34;clock&#34;]`
        then the seed is from the clock (for each xp),
        which would not provide exact reproducibility.
    &#34;&#34;&#34;
    set_seed(getattr(xp, &#39;seed&#39;, False))

    xx, yy = HMM.simulate()
    return xx, yy</code></pre>
</details>
</dd>
<dt id="dapper.admin.run_experiment"><code class="name flex">
<span>def <span class="ident">run_experiment</span></span>(<span>xp, label, savedir, HMM, setup=None, free=True, statkeys=False, fail_gently=False, **stat_kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Used by <code><a title="dapper.admin.xpList.launch" href="#dapper.admin.xpList.launch">xpList.launch()</a></code> to run each single experiment.</p>
<p>This involves steps similar to <code>example_1.py</code>, i.e.:</p>
<ul>
<li><code>setup</code>
: Call function given by user. Should set
params, eg HMM.Force, seed, and return
(simulated/loaded) truth and obs series.</li>
<li><code>xp.assimilate</code>
: run DA, pass on exception if fail_gently</li>
<li><code>xp.stats.average_in_time</code> : result averaging</li>
<li><code>xp.avrgs.tabulate</code>
: result printing</li>
<li><code>dill.dump</code>
: result storage</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_experiment(xp, label, savedir, HMM,
                   setup=None, free=True, statkeys=False, fail_gently=False,
                   **stat_kwargs):
    &#34;&#34;&#34;Used by `xpList.launch` to run each single experiment.

    This involves steps similar to `example_1.py`, i.e.:

    - `setup`                    : Call function given by user. Should set
                                   params, eg HMM.Force, seed, and return
                                   (simulated/loaded) truth and obs series.
    - `xp.assimilate`            : run DA, pass on exception if fail_gently
    - `xp.stats.average_in_time` : result averaging
    - `xp.avrgs.tabulate`        : result printing
    - `dill.dump`                : result storage
    &#34;&#34;&#34;

    # We should copy HMM so as not to cause any nasty surprises such as
    # expecting param=1 when param=2 (coz it&#39;s not been reset).
    # NB: won&#39;t copy implicitly ref&#39;d obj&#39;s (like L96&#39;s core). =&gt; bug w/ MP?
    hmm = copy.deepcopy(HMM)

    # GENERATE TRUTH/OBS
    xx, yy = setup(hmm, xp)

    # ASSIMILATE
    try:
        xp.assimilate(hmm, xx, yy, label, **stat_kwargs)
    except Exception as ERR:
        if fail_gently:
            xp.crashed = True
            if fail_gently not in [&#34;silent&#34;, &#34;quiet&#34;]:
                utils.print_cropped_traceback(ERR)
        else:
            raise ERR

    # AVERAGE
    xp.stats.average_in_time(free=free)

    # PRINT
    if statkeys:
        statkeys = () if statkeys is True else statkeys
        print(xp.avrgs.tabulate(statkeys))

    # SAVE
    if savedir:
        with open(Path(savedir)/&#34;xp&#34;, &#34;wb&#34;) as FILE:
            dill.dump({&#39;xp&#39;: xp}, FILE)</code></pre>
</details>
</dd>
<dt id="dapper.admin.get_param_setter"><code class="name flex">
<span>def <span class="ident">get_param_setter</span></span>(<span>param_dict, **glob_dict)</span>
</code></dt>
<dd>
<div class="desc"><p>Mass creation of <code>xp</code>'s by combining the value lists in the parameter dicts.</p>
<p>The parameters are trimmed to the ones available for the given method.
This is a good deal more efficient than relying on xpList's unique=True.</p>
<p>Beware! If, eg., <code>infl</code> or <code>rot</code> are in the param_dict, aimed at the EnKF,
but you forget that they are also attributes some method where you don't
actually want to use them (eg. SVGDF),
then you'll create many more than you intend.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_param_setter(param_dict, **glob_dict):
    &#34;&#34;&#34;Mass creation of `xp`&#39;s by combining the value lists in the parameter dicts.

    The parameters are trimmed to the ones available for the given method.
    This is a good deal more efficient than relying on xpList&#39;s unique=True.

    Beware! If, eg., `infl` or `rot` are in the param_dict, aimed at the EnKF,
    but you forget that they are also attributes some method where you don&#39;t
    actually want to use them (eg. SVGDF),
    then you&#39;ll create many more than you intend.
    &#34;&#34;&#34;
    def for_params(method, **fixed_params):
        dc_fields = [f.name for f in dcs.fields(method)]
        params = dict_tools.intersect(param_dict, dc_fields)
        params = dict_tools.complement(params, fixed_params)
        params = {**glob_dict, **params}  # glob_dict 1st

        def xp1(dct):
            xp = method(**dict_tools.intersect(dct, dc_fields), **fixed_params)
            for key, v in dict_tools.intersect(dct, glob_dict).items():
                setattr(xp, key, v)
            return xp

        return [xp1(dct) for dct in dict_tools.prodct(params)]
    return for_params</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dapper.admin.HiddenMarkovModel"><code class="flex name class">
<span>class <span class="ident">HiddenMarkovModel</span></span>
<span>(</span><span>Dyn, Obs, t, X0, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Container for a Hidden Markov Model (HMM).</p>
<p>This container contains the specification of a "twin experiment",
i.e. an "OSSE (observing system simulation experiment)".</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HiddenMarkovModel(dict_tools.NicePrint):
    &#34;&#34;&#34;Container for a Hidden Markov Model (HMM).

    This container contains the specification of a &#34;twin experiment&#34;,
    i.e. an &#34;OSSE (observing system simulation experiment)&#34;.
    &#34;&#34;&#34;

    def __init__(self, Dyn, Obs, t, X0, **kwargs):
        # fmt: off
        self.Dyn = Dyn if isinstance(Dyn, Operator)   else Operator  (**Dyn) # noqa
        self.Obs = Obs if isinstance(Obs, Operator)   else Operator  (**Obs) # noqa
        self.t   = t   if isinstance(t  , Chronology) else Chronology(**t)   # noqa
        self.X0  = X0  if isinstance(X0 , RV)         else RV        (**X0)  # noqa
        # fmt: on

        # Name
        self.name = kwargs.pop(&#34;name&#34;, &#34;&#34;)
        if not self.name:
            name = inspect.getfile(inspect.stack()[1][0])
            try:
                self.name = str(Path(name).relative_to(rc.dirs.dapper/&#39;mods&#39;))
            except ValueError:
                self.name = str(Path(name))

        # Kwargs
        abbrevs = {&#39;LP&#39;: &#39;liveplotters&#39;}
        for key in kwargs:
            setattr(self, abbrevs.get(key, key), kwargs[key])

        # Defaults
        if not hasattr(self.Obs, &#34;localizer&#34;):
            self.Obs.localizer = no_localization(self.Nx, self.Ny)
        if not hasattr(self, &#34;sectors&#34;):
            self.sectors = {}

        # Validation
        if self.Obs.noise.C == 0 or self.Obs.noise.C.rk != self.Obs.noise.C.M:
            raise ValueError(&#34;Rank-deficient R not supported.&#34;)

    # ndim shortcuts
    @property
    def Nx(self): return self.Dyn.M
    @property
    def Ny(self): return self.Obs.M

    printopts = {&#39;ordering&#39;: [&#39;Dyn&#39;, &#39;Obs&#39;, &#39;t&#39;, &#39;X0&#39;]}

    def simulate(self, desc=&#39;Truth &amp; Obs&#39;):
        &#34;&#34;&#34;Generate synthetic truth and observations.&#34;&#34;&#34;
        Dyn, Obs, chrono, X0 = self.Dyn, self.Obs, self.t, self.X0

        # Init
        xx    = np.zeros((chrono.K   + 1, Dyn.M))
        yy    = np.zeros((chrono.KObs+1, Obs.M))

        xx[0] = X0.sample(1)

        # Loop
        for k, kObs, t, dt in utils.progbar(chrono.ticker, desc):
            xx[k] = Dyn(xx[k-1], t-dt, dt) + np.sqrt(dt)*Dyn.noise.sample(1)
            if kObs is not None:
                yy[kObs] = Obs(xx[k], t) + Obs.noise.sample(1)

        return xx, yy</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dapper.dict_tools.NicePrint" href="dict_tools.html#dapper.dict_tools.NicePrint">NicePrint</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dapper.admin.HiddenMarkovModel.printopts"><code class="name">var <span class="ident">printopts</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="dapper.admin.HiddenMarkovModel.Nx"><code class="name">var <span class="ident">Nx</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def Nx(self): return self.Dyn.M</code></pre>
</details>
</dd>
<dt id="dapper.admin.HiddenMarkovModel.Ny"><code class="name">var <span class="ident">Ny</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def Ny(self): return self.Obs.M</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.admin.HiddenMarkovModel.simulate"><code class="name flex">
<span>def <span class="ident">simulate</span></span>(<span>self, desc='Truth & Obs')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate synthetic truth and observations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate(self, desc=&#39;Truth &amp; Obs&#39;):
    &#34;&#34;&#34;Generate synthetic truth and observations.&#34;&#34;&#34;
    Dyn, Obs, chrono, X0 = self.Dyn, self.Obs, self.t, self.X0

    # Init
    xx    = np.zeros((chrono.K   + 1, Dyn.M))
    yy    = np.zeros((chrono.KObs+1, Obs.M))

    xx[0] = X0.sample(1)

    # Loop
    for k, kObs, t, dt in utils.progbar(chrono.ticker, desc):
        xx[k] = Dyn(xx[k-1], t-dt, dt) + np.sqrt(dt)*Dyn.noise.sample(1)
        if kObs is not None:
            yy[kObs] = Obs(xx[k], t) + Obs.noise.sample(1)

    return xx, yy</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dapper.admin.Operator"><code class="flex name class">
<span>class <span class="ident">Operator</span></span>
<span>(</span><span>M, model=None, noise=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Container for operators (models).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Operator(dict_tools.NicePrint):
    &#34;&#34;&#34;Container for operators (models).&#34;&#34;&#34;

    def __init__(self, M, model=None, noise=None, **kwargs):
        self.M = M

        # None =&gt; Identity model
        if model is None:
            model = Id_op()
            kwargs[&#39;linear&#39;] = lambda x, t, dt: Id_mat(M)
        self.model = model

        # None/0 =&gt; No noise
        if isinstance(noise, RV):
            self.noise = noise
        else:
            if noise is None:
                noise = 0
            if np.isscalar(noise):
                self.noise = GaussRV(C=noise, M=M)
            else:
                self.noise = GaussRV(C=noise)

        # Write attributes
        for key, value in kwargs.items():
            setattr(self, key, value)

    def __call__(self, *args, **kwargs):
        return self.model(*args, **kwargs)

    printopts = {&#39;ordering&#39;: [&#39;M&#39;, &#39;model&#39;, &#39;noise&#39;]}</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="dapper.dict_tools.NicePrint" href="dict_tools.html#dapper.dict_tools.NicePrint">NicePrint</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="dapper.admin.Operator.printopts"><code class="name">var <span class="ident">printopts</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="dapper.admin.xpList"><code class="flex name class">
<span>class <span class="ident">xpList</span></span>
<span>(</span><span>*args, unique=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Subclass of <code>list</code> specialized for experiment ("xp") objects.</p>
<p>Main use: administrate experiment <strong>launches</strong>.
Also see: <code>xpSpace</code> for experiment <strong>result presentation</strong>.</p>
<p>Modifications to <code>list</code>:</p>
<ul>
<li><code>__iadd__</code> (append) also for single items;
this is hackey, but convenience is king.</li>
<li><code>append()</code> supports <code>unique</code> to enable lazy xp declaration.</li>
<li><code>__getitem__</code> supports lists.</li>
<li>pretty printing (using common/distinct attrs).</li>
</ul>
<p>Add-ons:</p>
<ul>
<li><code>launch()</code></li>
<li><code>print_averages()</code></li>
<li><code>gen_names()</code></li>
<li><code>inds()</code> to search by kw-attrs.</li>
</ul>
<p>Initialize without args, or with a list of <code>xp</code>s.</p>
<p>If <code>unique</code>: duplicates won't get appended.
This makes <code>append()</code> (and <code>__iadd__()</code>) relatively slow.
Use <code>extend()</code> or <code>__add__()</code> to bypass this validation.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class xpList(list):
    &#34;&#34;&#34;Subclass of `list` specialized for experiment (&#34;xp&#34;) objects.

    Main use: administrate experiment **launches**.
    Also see: `xpSpace` for experiment **result presentation**.

    Modifications to `list`:

    - `__iadd__` (append) also for single items;
      this is hackey, but convenience is king.
    - `append()` supports `unique` to enable lazy xp declaration.
    - `__getitem__` supports lists.
    - pretty printing (using common/distinct attrs).

    Add-ons:

    - `launch()`
    - `print_averages()`
    - `gen_names()`
    - `inds()` to search by kw-attrs.
    &#34;&#34;&#34;

    def __init__(self, *args, unique=False):
        &#34;&#34;&#34;Initialize without args, or with a list of `xp`s.

        If `unique`: duplicates won&#39;t get appended.
        This makes `append()` (and `__iadd__()`) relatively slow.
        Use `extend()` or `__add__()` to bypass this validation.&#34;&#34;&#34;

        self.unique = unique
        super().__init__(*args)

    def __iadd__(self, xp):
        if not hasattr(xp, &#39;__iter__&#39;):
            xp = [xp]
        for item in xp:
            self.append(item)
        return self

    def append(self, xp):
        &#34;&#34;&#34;Append if not `self.unique` &amp; present.&#34;&#34;&#34;
        if not (self.unique and xp in self):
            super().append(xp)

    def __getitem__(self, keys):
        &#34;&#34;&#34;Indexing, also by a list&#34;&#34;&#34;
        try:
            B = [self[k] for k in keys]    # if keys is list
        except TypeError:
            B = super().__getitem__(keys)  # if keys is int, slice
        if hasattr(B, &#39;__len__&#39;):
            B = xpList(B)                  # Cast
        return B

    def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
        &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

        If strict, then `xp`s lacking a requested attr will not match,
        unless the missingval (e.g. `None`) matches the required value.
        &#34;&#34;&#34;
        def match(xp):
            def missing(v): return missingval if strict else v
            matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
            return all(matches)

        return [i for i, xp in enumerate(self) if match(xp)]

    @property
    def da_methods(self):
        return [xp.da_method for xp in self]

    def split_attrs(self, nomerge=()):
        &#34;&#34;&#34;Compile attrs of all `xp`s; split into distinct, redundant, common.

        Insert `None` if an attribute is distinct but not in `xp`.&#34;&#34;&#34;

        def _aggregate_keys():
            &#34;Aggregate keys from all `xp`&#34;

            if len(self) == 0:
                return []

            # Start with da_method
            aggregate = [&#39;da_method&#39;]

            # Aggregate all other keys
            for xp in self:

                # Get dataclass fields
                try:
                    dc_fields = dcs.fields(xp.__class__)
                    dc_names = [F.name for F in dc_fields]
                    keys = xp.__dict__.keys()
                except TypeError:
                    # Assume namedtuple
                    dc_names = []
                    keys = xp._fields

                # For all potential keys:
                for k in keys:
                    # If not already present:
                    if k not in aggregate:

                        # If dataclass, check repr:
                        if k in dc_names:
                            if dc_fields[dc_names.index(k)].repr:
                                aggregate.append(k)
                        # Else, just append
                        else:
                            aggregate.append(k)

            # Remove unwanted
            excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
            aggregate = dict_tools.complement(aggregate, excluded)
            return aggregate

        distinct, redundant, common = {}, {}, {}

        for key in _aggregate_keys():

            # Want to distinguish actual None&#39;s from empty (&#34;N/A&#34;).
            # =&gt; Don&#39;t use getattr(obj,key,None)
            vals = [getattr(xp, key, &#34;N/A&#34;) for xp in self]

            # Sort (assign dct) into distinct, redundant, common
            if dict_tools.flexcomp(key, *nomerge):
                # nomerge =&gt; Distinct
                dct, vals = distinct, vals
            elif all(vals[0] == v for v in vals):
                # all values equal =&gt; common
                dct, vals = common, vals[0]
            else:
                v0 = next(v for v in vals if &#34;N/A&#34; != v)
                if all(v == &#34;N/A&#34; or v == v0 for v in vals):
                    # all values equal or &#34;N/A&#34; =&gt; redundant
                    dct, vals = redundant, v0
                else:
                    # otherwise =&gt; distinct
                    dct, vals = distinct, vals

            # Replace &#34;N/A&#34; by None
            def sub(v): return None if v == &#34;N/A&#34; else v
            if isinstance(vals, str):
                vals = sub(vals)
            else:
                try:
                    vals = [sub(v) for v in vals]
                except TypeError:
                    vals = sub(vals)

            dct[key] = vals

        return distinct, redundant, common

    def __repr__(self):
        distinct, redundant, common = self.split_attrs()
        s = &#39;&lt;xpList&gt; of length %d with attributes:\n&#39; % len(self)
        s += utils.tab(distinct, headers=&#34;keys&#34;, showindex=True)
        s += &#34;\nOther attributes:\n&#34;
        s += str(dict_tools.AlignedDict({**redundant, **common}))
        return s

    def gen_names(self, abbrev=6, tab=False):
        &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

        - returns *list* of names
        - tabulation is optional
        - attaches (abbreviated) labels to each attribute
        &#34;&#34;&#34;
        distinct, redundant, common = self.split_attrs(nomerge=[&#34;da_method&#34;])
        labels = distinct.keys()
        values = distinct.values()

        # Label abbreviation
        labels = [utils.collapse_str(k, abbrev) for k in labels]

        # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
        def column(lbl, vals):
            return [None if v is None else lbl+&#34;:&#34; for v in vals]
        labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

        # Interlace labels and values
        table = [x for (a, b) in zip(labels, values) for x in (a, b)]

        # Rm da_method label (but keep value)
        table.pop(0)

        # Transpose
        table = list(map(list, zip(*table)))

        # Tabulate
        table = utils.tab(table, tablefmt=&#34;plain&#34;)

        # Rm space between lbls/vals
        table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

        # Rm alignment
        if not tab:
            table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

        return table.splitlines()

    def tabulate_avrgs(self, *args, **kwargs):
        &#34;&#34;&#34;Pretty (tabulated) `repr` of `xps` &amp; their `avrgs.`

        Similar to `stats.tabulate_avrgs`, but for the entire list of `xps`.&#34;&#34;&#34;
        distinct, redundant, common = self.split_attrs()
        averages = dapper.stats.tabulate_avrgs([C.avrgs for C in self], *args, **kwargs)
        columns = {**distinct, &#39;|&#39;: [&#39;|&#39;]*len(self), **averages}  # merge
        return utils.tab(columns, headers=&#34;keys&#34;, showindex=True).replace(&#39;␣&#39;, &#39; &#39;)

    def launch(self, HMM, save_as=&#34;noname&#34;, mp=False,
               setup=seed_and_simulate, fail_gently=None, **kwargs):
        &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

        The results are saved in `rc.dirs[&#39;data&#39;]/save_as`,
        unless `save_as` is False/None.

        Depending on `mp`, `run_experiment` is delegated as follows:

        - `False`: caller process (no parallelisation)
        - `True` or &#34;MP&#34; or an `int`: multiprocessing on this host
        - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
          (Google Cloud Computing with HTCondor).
            - Specify a list of files as `mp[&#34;files&#34;]` to include them
              in working directory of the server workers.
            - In order to use absolute paths, the list should cosist
              of tuples, where the first item is relative to the second
              (which is an absolute path). The root is then not included
              in the working directory of the server.
            - If this dict field is empty, then all python files
              in `sys.path[0]` are uploaded.

        If `setup == None`: use `seed_and_simulate`.
        Specify your own setup function
        (possibly calling `seed_and_simulate`)
        in order to set (general) experiment parameters that are not
        (i.e. those that are not inherently used by the da_method
        of that `xp`).

        See `example_2.py` and `example_3.py` for example use.
        &#34;&#34;&#34;

        # Collect common args forwarded to run_experiment
        kwargs[&#39;HMM&#39;] = HMM
        kwargs[&#34;setup&#34;] = setup

        # Parse mp option
        if not mp:
            mp = dict()
        elif mp in [True, &#34;MP&#34;]:
            mp = dict(server=&#34;local&#34;)
        elif isinstance(mp, int):
            mp = dict(server=&#34;local&#34;, NPROC=mp)
        elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
            mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

        # Parse fail_gently
        if fail_gently is None:
            if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
                fail_gently = False
                # coz cloud processing is entirely de-coupled anyways
            else:
                fail_gently = True
                # True unless otherwise requested
        kwargs[&#34;fail_gently&#34;] = fail_gently

        # Parse save_as
        if save_as in [None, False]:
            assert not mp, &#34;Multiprocessing requires saving data.&#34;
            # Parallelization w/o storing is possible, especially w/ threads.
            # But it involves more complicated communication set-up.
            def xpi_dir(*args): return None
        else:
            save_as = rc.dirs.data / Path(save_as).stem
            save_as /= &#34;run_&#34; + datetime.now().strftime(&#34;%Y-%m-%d__%H:%M:%S&#34;)
            os.makedirs(save_as)
            print(f&#34;Experiment stored at {save_as}&#34;)

            def xpi_dir(i):
                path = save_as / str(i)
                os.mkdir(path)
                return path

        # No parallelization
        if not mp:
            for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
                run_experiment(xp, label, xpi_dir(ixp), **kwargs)

        # Local multiprocessing
        elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
            def run_with_fixed_args(arg):
                xp, ixp = arg
                run_experiment(xp, None, xpi_dir(ixp), **kwargs)
            args = zip(self, range(len(self)))

            utils.disable_progbar          = True
            utils.disable_user_interaction = True
            NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
            from dapper.tools.multiproc import mpd  # will fail on GCP
            with mpd.Pool(NPROC) as pool:
                list(utils.tqdm.tqdm(
                    pool.imap(
                        run_with_fixed_args, args),
                    total=len(self),
                    desc=&#34;Parallel experim&#39;s&#34;,
                    smoothing=0.1))
            utils.disable_progbar          = False
            utils.disable_user_interaction = False

        # Google cloud platform, multiprocessing
        elif mp[&#34;server&#34;] == &#34;GCP&#34;:
            for ixp, xp in enumerate(self):
                with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                    dill.dump(dict(xp=xp), f)

            with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
                dill.dump(kwargs, f)

            # mkdir extra_files
            extra_files = save_as / &#34;extra_files&#34;
            os.mkdir(extra_files)
            # Default files: .py files in sys.path[0] (main script&#39;s path)
            if not mp.get(&#34;files&#34;, []):
                ff = os.listdir(sys.path[0])
                mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
            # Copy files into extra_files
            for f in mp[&#34;files&#34;]:
                if isinstance(f, (str, Path)):
                    # Example: f = &#34;A.py&#34;
                    path = Path(sys.path[0]) / f
                    dst = f
                else:  # instance of tuple(path, root)
                    # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                    path, root = f
                    dst = Path(path).relative_to(root)
                dst = extra_files / dst
                os.makedirs(dst.parent, exist_ok=True)
                try:
                    shutil.copytree(path, dst)  # dir -r
                except OSError:
                    shutil.copy2(path, dst)  # file

            # Loads PWD/xp_{var,com} and calls run_experiment()
            with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
                f.write(dedent(&#34;&#34;&#34;\
                import dill
                from dapper.admin import run_experiment

                # Load
                with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
                with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

                # User-defined code
                %s

                # Run
                result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
                &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

            with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
                f.write(&#34;\n&#34;.join([
                    &#34;data_root: &#39;$cwd&#39;&#34;,
                    &#34;liveplotting: no&#34;,
                    &#34;welcome_message: no&#34;]))
            submit_job_GCP(save_as)

        return save_as</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.list</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="dapper.admin.xpList.da_methods"><code class="name">var <span class="ident">da_methods</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def da_methods(self):
    return [xp.da_method for xp in self]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dapper.admin.xpList.append"><code class="name flex">
<span>def <span class="ident">append</span></span>(<span>self, xp)</span>
</code></dt>
<dd>
<div class="desc"><p>Append if not <code>self.unique</code> &amp; present.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def append(self, xp):
    &#34;&#34;&#34;Append if not `self.unique` &amp; present.&#34;&#34;&#34;
    if not (self.unique and xp in self):
        super().append(xp)</code></pre>
</details>
</dd>
<dt id="dapper.admin.xpList.inds"><code class="name flex">
<span>def <span class="ident">inds</span></span>(<span>self, strict=True, missingval='NONSENSE', **kws)</span>
</code></dt>
<dd>
<div class="desc"><p>Find (all) indices of <code>xps</code> whose attributes match kws.</p>
<p>If strict, then <code>xp</code>s lacking a requested attr will not match,
unless the missingval (e.g. <code>None</code>) matches the required value.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def inds(self, strict=True, missingval=&#34;NONSENSE&#34;, **kws):
    &#34;&#34;&#34;Find (all) indices of `xps` whose attributes match kws.

    If strict, then `xp`s lacking a requested attr will not match,
    unless the missingval (e.g. `None`) matches the required value.
    &#34;&#34;&#34;
    def match(xp):
        def missing(v): return missingval if strict else v
        matches = [getattr(xp, k, missing(v)) == v for k, v in kws.items()]
        return all(matches)

    return [i for i, xp in enumerate(self) if match(xp)]</code></pre>
</details>
</dd>
<dt id="dapper.admin.xpList.split_attrs"><code class="name flex">
<span>def <span class="ident">split_attrs</span></span>(<span>self, nomerge=())</span>
</code></dt>
<dd>
<div class="desc"><p>Compile attrs of all <code>xp</code>s; split into distinct, redundant, common.</p>
<p>Insert <code>None</code> if an attribute is distinct but not in <code>xp</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_attrs(self, nomerge=()):
    &#34;&#34;&#34;Compile attrs of all `xp`s; split into distinct, redundant, common.

    Insert `None` if an attribute is distinct but not in `xp`.&#34;&#34;&#34;

    def _aggregate_keys():
        &#34;Aggregate keys from all `xp`&#34;

        if len(self) == 0:
            return []

        # Start with da_method
        aggregate = [&#39;da_method&#39;]

        # Aggregate all other keys
        for xp in self:

            # Get dataclass fields
            try:
                dc_fields = dcs.fields(xp.__class__)
                dc_names = [F.name for F in dc_fields]
                keys = xp.__dict__.keys()
            except TypeError:
                # Assume namedtuple
                dc_names = []
                keys = xp._fields

            # For all potential keys:
            for k in keys:
                # If not already present:
                if k not in aggregate:

                    # If dataclass, check repr:
                    if k in dc_names:
                        if dc_fields[dc_names.index(k)].repr:
                            aggregate.append(k)
                    # Else, just append
                    else:
                        aggregate.append(k)

        # Remove unwanted
        excluded  = [re.compile(&#39;^_&#39;), &#39;avrgs&#39;, &#39;stats&#39;, &#39;HMM&#39;, &#39;duration&#39;]
        aggregate = dict_tools.complement(aggregate, excluded)
        return aggregate

    distinct, redundant, common = {}, {}, {}

    for key in _aggregate_keys():

        # Want to distinguish actual None&#39;s from empty (&#34;N/A&#34;).
        # =&gt; Don&#39;t use getattr(obj,key,None)
        vals = [getattr(xp, key, &#34;N/A&#34;) for xp in self]

        # Sort (assign dct) into distinct, redundant, common
        if dict_tools.flexcomp(key, *nomerge):
            # nomerge =&gt; Distinct
            dct, vals = distinct, vals
        elif all(vals[0] == v for v in vals):
            # all values equal =&gt; common
            dct, vals = common, vals[0]
        else:
            v0 = next(v for v in vals if &#34;N/A&#34; != v)
            if all(v == &#34;N/A&#34; or v == v0 for v in vals):
                # all values equal or &#34;N/A&#34; =&gt; redundant
                dct, vals = redundant, v0
            else:
                # otherwise =&gt; distinct
                dct, vals = distinct, vals

        # Replace &#34;N/A&#34; by None
        def sub(v): return None if v == &#34;N/A&#34; else v
        if isinstance(vals, str):
            vals = sub(vals)
        else:
            try:
                vals = [sub(v) for v in vals]
            except TypeError:
                vals = sub(vals)

        dct[key] = vals

    return distinct, redundant, common</code></pre>
</details>
</dd>
<dt id="dapper.admin.xpList.gen_names"><code class="name flex">
<span>def <span class="ident">gen_names</span></span>(<span>self, abbrev=6, tab=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Similiar to <code>self.__repr__()</code>, but:</p>
<ul>
<li>returns <em>list</em> of names</li>
<li>tabulation is optional</li>
<li>attaches (abbreviated) labels to each attribute</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gen_names(self, abbrev=6, tab=False):
    &#34;&#34;&#34;Similiar to `self.__repr__()`, but:

    - returns *list* of names
    - tabulation is optional
    - attaches (abbreviated) labels to each attribute
    &#34;&#34;&#34;
    distinct, redundant, common = self.split_attrs(nomerge=[&#34;da_method&#34;])
    labels = distinct.keys()
    values = distinct.values()

    # Label abbreviation
    labels = [utils.collapse_str(k, abbrev) for k in labels]

    # Make label columns: insert None or lbl+&#34;:&#34;, depending on value
    def column(lbl, vals):
        return [None if v is None else lbl+&#34;:&#34; for v in vals]
    labels = [column(lbl, vals) for lbl, vals in zip(labels, values)]

    # Interlace labels and values
    table = [x for (a, b) in zip(labels, values) for x in (a, b)]

    # Rm da_method label (but keep value)
    table.pop(0)

    # Transpose
    table = list(map(list, zip(*table)))

    # Tabulate
    table = utils.tab(table, tablefmt=&#34;plain&#34;)

    # Rm space between lbls/vals
    table = re.sub(&#39;:  +&#39;, &#39;:&#39;, table)

    # Rm alignment
    if not tab:
        table = re.sub(r&#39; +&#39;, r&#39; &#39;, table)

    return table.splitlines()</code></pre>
</details>
</dd>
<dt id="dapper.admin.xpList.tabulate_avrgs"><code class="name flex">
<span>def <span class="ident">tabulate_avrgs</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Pretty (tabulated) <code>repr</code> of <code>xps</code> &amp; their <code>avrgs.</code></p>
<p>Similar to <code>stats.tabulate_avrgs</code>, but for the entire list of <code>xps</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tabulate_avrgs(self, *args, **kwargs):
    &#34;&#34;&#34;Pretty (tabulated) `repr` of `xps` &amp; their `avrgs.`

    Similar to `stats.tabulate_avrgs`, but for the entire list of `xps`.&#34;&#34;&#34;
    distinct, redundant, common = self.split_attrs()
    averages = dapper.stats.tabulate_avrgs([C.avrgs for C in self], *args, **kwargs)
    columns = {**distinct, &#39;|&#39;: [&#39;|&#39;]*len(self), **averages}  # merge
    return utils.tab(columns, headers=&#34;keys&#34;, showindex=True).replace(&#39;␣&#39;, &#39; &#39;)</code></pre>
</details>
</dd>
<dt id="dapper.admin.xpList.launch"><code class="name flex">
<span>def <span class="ident">launch</span></span>(<span>self, HMM, save_as='noname', mp=False, setup=&lt;function seed_and_simulate&gt;, fail_gently=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Essentially: <code>for xp in self: run_experiment(xp, ..., **kwargs)</code>.</p>
<p>The results are saved in <code>rc.dirs['data']/save_as</code>,
unless <code>save_as</code> is False/None.</p>
<p>Depending on <code>mp</code>, <code><a title="dapper.admin.run_experiment" href="#dapper.admin.run_experiment">run_experiment()</a></code> is delegated as follows:</p>
<ul>
<li><code>False</code>: caller process (no parallelisation)</li>
<li><code>True</code> or "MP" or an <code>int</code>: multiprocessing on this host</li>
<li><code>"GCP"</code> or <code>"Google"</code> or <code>dict(server="GCP")</code>: the DAPPER server
(Google Cloud Computing with HTCondor).<ul>
<li>Specify a list of files as <code>mp["files"]</code> to include them
in working directory of the server workers.</li>
<li>In order to use absolute paths, the list should cosist
of tuples, where the first item is relative to the second
(which is an absolute path). The root is then not included
in the working directory of the server.</li>
<li>If this dict field is empty, then all python files
in <code>sys.path[0]</code> are uploaded.</li>
</ul>
</li>
</ul>
<p>If <code>setup == None</code>: use <code><a title="dapper.admin.seed_and_simulate" href="#dapper.admin.seed_and_simulate">seed_and_simulate()</a></code>.
Specify your own setup function
(possibly calling <code><a title="dapper.admin.seed_and_simulate" href="#dapper.admin.seed_and_simulate">seed_and_simulate()</a></code>)
in order to set (general) experiment parameters that are not
(i.e. those that are not inherently used by the da_method
of that <code>xp</code>).</p>
<p>See <code>example_2.py</code> and <code>example_3.py</code> for example use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def launch(self, HMM, save_as=&#34;noname&#34;, mp=False,
           setup=seed_and_simulate, fail_gently=None, **kwargs):
    &#34;&#34;&#34;Essentially: `for xp in self: run_experiment(xp, ..., **kwargs)`.

    The results are saved in `rc.dirs[&#39;data&#39;]/save_as`,
    unless `save_as` is False/None.

    Depending on `mp`, `run_experiment` is delegated as follows:

    - `False`: caller process (no parallelisation)
    - `True` or &#34;MP&#34; or an `int`: multiprocessing on this host
    - `&#34;GCP&#34;` or `&#34;Google&#34;` or `dict(server=&#34;GCP&#34;)`: the DAPPER server
      (Google Cloud Computing with HTCondor).
        - Specify a list of files as `mp[&#34;files&#34;]` to include them
          in working directory of the server workers.
        - In order to use absolute paths, the list should cosist
          of tuples, where the first item is relative to the second
          (which is an absolute path). The root is then not included
          in the working directory of the server.
        - If this dict field is empty, then all python files
          in `sys.path[0]` are uploaded.

    If `setup == None`: use `seed_and_simulate`.
    Specify your own setup function
    (possibly calling `seed_and_simulate`)
    in order to set (general) experiment parameters that are not
    (i.e. those that are not inherently used by the da_method
    of that `xp`).

    See `example_2.py` and `example_3.py` for example use.
    &#34;&#34;&#34;

    # Collect common args forwarded to run_experiment
    kwargs[&#39;HMM&#39;] = HMM
    kwargs[&#34;setup&#34;] = setup

    # Parse mp option
    if not mp:
        mp = dict()
    elif mp in [True, &#34;MP&#34;]:
        mp = dict(server=&#34;local&#34;)
    elif isinstance(mp, int):
        mp = dict(server=&#34;local&#34;, NPROC=mp)
    elif mp in [&#34;GCP&#34;, &#34;Google&#34;]:
        mp = dict(server=&#34;GCP&#34;, files=[], code=&#34;&#34;)

    # Parse fail_gently
    if fail_gently is None:
        if mp and mp[&#34;server&#34;] == &#34;GCP&#34;:
            fail_gently = False
            # coz cloud processing is entirely de-coupled anyways
        else:
            fail_gently = True
            # True unless otherwise requested
    kwargs[&#34;fail_gently&#34;] = fail_gently

    # Parse save_as
    if save_as in [None, False]:
        assert not mp, &#34;Multiprocessing requires saving data.&#34;
        # Parallelization w/o storing is possible, especially w/ threads.
        # But it involves more complicated communication set-up.
        def xpi_dir(*args): return None
    else:
        save_as = rc.dirs.data / Path(save_as).stem
        save_as /= &#34;run_&#34; + datetime.now().strftime(&#34;%Y-%m-%d__%H:%M:%S&#34;)
        os.makedirs(save_as)
        print(f&#34;Experiment stored at {save_as}&#34;)

        def xpi_dir(i):
            path = save_as / str(i)
            os.mkdir(path)
            return path

    # No parallelization
    if not mp:
        for ixp, (xp, label) in enumerate(zip(self, self.gen_names())):
            run_experiment(xp, label, xpi_dir(ixp), **kwargs)

    # Local multiprocessing
    elif mp[&#34;server&#34;].lower() == &#34;local&#34;:
        def run_with_fixed_args(arg):
            xp, ixp = arg
            run_experiment(xp, None, xpi_dir(ixp), **kwargs)
        args = zip(self, range(len(self)))

        utils.disable_progbar          = True
        utils.disable_user_interaction = True
        NPROC = mp.get(&#34;NPROC&#34;, None)  # None =&gt; mp.cpu_count()
        from dapper.tools.multiproc import mpd  # will fail on GCP
        with mpd.Pool(NPROC) as pool:
            list(utils.tqdm.tqdm(
                pool.imap(
                    run_with_fixed_args, args),
                total=len(self),
                desc=&#34;Parallel experim&#39;s&#34;,
                smoothing=0.1))
        utils.disable_progbar          = False
        utils.disable_user_interaction = False

    # Google cloud platform, multiprocessing
    elif mp[&#34;server&#34;] == &#34;GCP&#34;:
        for ixp, xp in enumerate(self):
            with open(xpi_dir(ixp)/&#34;xp.var&#34;, &#34;wb&#34;) as f:
                dill.dump(dict(xp=xp), f)

        with open(save_as/&#34;xp.com&#34;, &#34;wb&#34;) as f:
            dill.dump(kwargs, f)

        # mkdir extra_files
        extra_files = save_as / &#34;extra_files&#34;
        os.mkdir(extra_files)
        # Default files: .py files in sys.path[0] (main script&#39;s path)
        if not mp.get(&#34;files&#34;, []):
            ff = os.listdir(sys.path[0])
            mp[&#34;files&#34;] = [f for f in ff if f.endswith(&#34;.py&#34;)]
        # Copy files into extra_files
        for f in mp[&#34;files&#34;]:
            if isinstance(f, (str, Path)):
                # Example: f = &#34;A.py&#34;
                path = Path(sys.path[0]) / f
                dst = f
            else:  # instance of tuple(path, root)
                # Example: f = (&#34;~/E/G/A.py&#34;, &#34;G&#34;)
                path, root = f
                dst = Path(path).relative_to(root)
            dst = extra_files / dst
            os.makedirs(dst.parent, exist_ok=True)
            try:
                shutil.copytree(path, dst)  # dir -r
            except OSError:
                shutil.copy2(path, dst)  # file

        # Loads PWD/xp_{var,com} and calls run_experiment()
        with open(extra_files/&#34;load_and_run.py&#34;, &#34;w&#34;) as f:
            f.write(dedent(&#34;&#34;&#34;\
            import dill
            from dapper.admin import run_experiment

            # Load
            with open(&#34;xp.com&#34;, &#34;rb&#34;) as f: com = dill.load(f)
            with open(&#34;xp.var&#34;, &#34;rb&#34;) as f: var = dill.load(f)

            # User-defined code
            %s

            # Run
            result = run_experiment(var[&#39;xp&#39;], None, &#34;.&#34;, **com)
            &#34;&#34;&#34;) % dedent(mp[&#34;code&#34;]))

        with open(extra_files/&#34;dpr_config.yaml&#34;, &#34;w&#34;) as f:
            f.write(&#34;\n&#34;.join([
                &#34;data_root: &#39;$cwd&#39;&#34;,
                &#34;liveplotting: no&#34;,
                &#34;welcome_message: no&#34;]))
        submit_job_GCP(save_as)

    return save_as</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="DAPPER" href="https://nansencenter.github.io/DAPPER">
<img src="https://raw.githubusercontent.com/nansencenter/DAPPER/master/docs/imgs/logo_wtxt.png" alt="">
<!-- can add style="width:200px;" to img -->
</a>
</header>
<div class="gcse-search" style="height: 70px"
data-as_oq="inurl:github.com/nansencenter/DAPPER site:DAPPER.github.io"
data-gaCategoryParameter="dapper.admin">
</div>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dapper" href="index.html">dapper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dapper.admin.da_method" href="#dapper.admin.da_method">da_method</a></code></li>
<li><code><a title="dapper.admin.seed_and_simulate" href="#dapper.admin.seed_and_simulate">seed_and_simulate</a></code></li>
<li><code><a title="dapper.admin.run_experiment" href="#dapper.admin.run_experiment">run_experiment</a></code></li>
<li><code><a title="dapper.admin.get_param_setter" href="#dapper.admin.get_param_setter">get_param_setter</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dapper.admin.HiddenMarkovModel" href="#dapper.admin.HiddenMarkovModel">HiddenMarkovModel</a></code></h4>
<ul class="">
<li><code><a title="dapper.admin.HiddenMarkovModel.simulate" href="#dapper.admin.HiddenMarkovModel.simulate">simulate</a></code></li>
<li><code><a title="dapper.admin.HiddenMarkovModel.Nx" href="#dapper.admin.HiddenMarkovModel.Nx">Nx</a></code></li>
<li><code><a title="dapper.admin.HiddenMarkovModel.Ny" href="#dapper.admin.HiddenMarkovModel.Ny">Ny</a></code></li>
<li><code><a title="dapper.admin.HiddenMarkovModel.printopts" href="#dapper.admin.HiddenMarkovModel.printopts">printopts</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.admin.Operator" href="#dapper.admin.Operator">Operator</a></code></h4>
<ul class="">
<li><code><a title="dapper.admin.Operator.printopts" href="#dapper.admin.Operator.printopts">printopts</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dapper.admin.xpList" href="#dapper.admin.xpList">xpList</a></code></h4>
<ul class="two-column">
<li><code><a title="dapper.admin.xpList.append" href="#dapper.admin.xpList.append">append</a></code></li>
<li><code><a title="dapper.admin.xpList.inds" href="#dapper.admin.xpList.inds">inds</a></code></li>
<li><code><a title="dapper.admin.xpList.split_attrs" href="#dapper.admin.xpList.split_attrs">split_attrs</a></code></li>
<li><code><a title="dapper.admin.xpList.gen_names" href="#dapper.admin.xpList.gen_names">gen_names</a></code></li>
<li><code><a title="dapper.admin.xpList.tabulate_avrgs" href="#dapper.admin.xpList.tabulate_avrgs">tabulate_avrgs</a></code></li>
<li><code><a title="dapper.admin.xpList.launch" href="#dapper.admin.xpList.launch">launch</a></code></li>
<li><code><a title="dapper.admin.xpList.da_methods" href="#dapper.admin.xpList.da_methods">da_methods</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>